{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.integrate\n",
    "import matplotlib.pyplot as plt\n",
    "import git\n",
    "import itertools\n",
    "from scipy.linalg import svd\n",
    "from scipy.optimize import least_squares\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data for each county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = git.Repo(\"./\", search_parent_directories=True)\n",
    "homedir = repo.working_dir\n",
    "datadir = f\"{homedir}/data/us/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COVID data (fips, county, cases, deaths) columns\n",
    "df = pd.read_csv(datadir + 'covid/nyt_us_counties.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# population data (FIPS, total_pop, 60plus)\n",
    "def get_population(fips, pop_df):\n",
    "    if np.isnan(fips):\n",
    "        return np.nan\n",
    "    return pop_df[pop_df['FIPS'] == fips]['total_pop'].values[0]\n",
    "\n",
    "pop_df = pd.read_csv(datadir + 'demographics/county_populations.csv')\n",
    "df['population'] = df.apply(lambda row: get_population(row.fips, pop_df), axis=1)\n",
    "df.loc[df['county'] == 'New York City', 'population'] = 8.399*(10**7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date_processed column \n",
    "df['date_processed'] = pd.to_datetime(df['date'].values)\n",
    "df['date_processed'] = (df['date_processed'] - df['date_processed'].min()) / np.timedelta64(1, 'D')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get all required FIPS codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sub = pd.read_csv(\"sample_submission.csv\")\n",
    "fips_list = []\n",
    "for label in sample_sub['id']:\n",
    "    fips_list.append(label.split('-')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {'id':'2020-04-01-10001'}\n",
    "for j in range(10, 100, 10):\n",
    "    dic[str(j)] = j\n",
    "sample_sub[sample_sub['id']=='2020-04-01-10001'] = dic.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model: SEIR-QD \n",
    "Parameters:  \n",
    "\n",
    " $\\beta$ = infection rate, from earlier plotting   \n",
    " $\\delta$ = recovery rate, which we think is on the order of 10-40 days.  \n",
    " $\\gamma$= transition of exposed individuals to infected, which we aren't sure of, especially with the unknown number of asymptomatics.   \n",
    " $\\alpha$ = protection rate of susceptible individuals, which we also don't know, and is most likely dynamic over the course of the outbreak.   \n",
    " $\\lambda$ = transition rate of infected to quarantined with infection, same as above.  \n",
    " $\\kappa$ = death rate, which we think is around 0.01-0.06. We will leave a range between 0.01 and 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seirqd(dat, t, params, N):\n",
    "    beta = params[0] / N\n",
    "    delta = params[1]\n",
    "    gamma = params[2]\n",
    "    alpha = params[3]\n",
    "    lambda_ = params[4]\n",
    "    kappa = params[5]\n",
    "    \n",
    "    s = dat[0]\n",
    "    e = dat[1]\n",
    "    i = dat[2]\n",
    "    q = dat[3]\n",
    "    r = dat[4]\n",
    "    d = dat[5]\n",
    "    sa = dat[6]\n",
    "    \n",
    "    dsdt = - beta * s * i - alpha * s\n",
    "    dedt = beta * s * i - gamma * e\n",
    "    didt = gamma * e - lambda_ * i\n",
    "    dqdt = lambda_ * i - delta * q - kappa * q\n",
    "    drdt = delta * q\n",
    "    dddt = kappa * q\n",
    "    dsadt = alpha * s\n",
    "    \n",
    "    # susceptible, exposed, infected, quarantined, recovered, died, unsusceptible\n",
    "    return [dsdt, dedt, didt, dqdt, drdt, dddt, dsadt]\n",
    "\n",
    "def model_qd(params, data, tmax=-1):\n",
    "    # initial conditions\n",
    "    N = data['population'].values[0] # total population\n",
    "    \n",
    "    # the parameters are a fraction of the population so multiply by the population\n",
    "    initial_conditions = N * np.array(params[-5:]) \n",
    "    \n",
    "    # initial conditions\n",
    "    e0 = initial_conditions[0]\n",
    "    i0 = initial_conditions[1]\n",
    "    q0 = initial_conditions[2]\n",
    "    r0 = initial_conditions[3]\n",
    "    sa0 = initial_conditions[4]\n",
    "    \n",
    "    d0 = data['deaths'].values[0]\n",
    "    s0 = N - np.sum(initial_conditions) - d0\n",
    "\n",
    "    yz_0 = np.array([s0, e0, i0, q0, r0, d0, sa0])\n",
    "    \n",
    "    # Package parameters into a tuple\n",
    "    args = (params, N)\n",
    "    \n",
    "    n = len(data)\n",
    "    if tmax > 0:\n",
    "        n = tmax\n",
    "    \n",
    "    # Integrate ODEs\n",
    "    s = scipy.integrate.odeint(seirqd, yz_0, np.arange(0, n), args=args)\n",
    "\n",
    "    return s\n",
    "\n",
    "def fit_leastsq_qd(params, data):\n",
    "    Ddata = (data['deaths'].values)\n",
    "    Idata = (data['cases'].values)\n",
    "    s = model_qd(params, data)\n",
    "\n",
    "    S = s[:,0]\n",
    "    E = s[:,1]\n",
    "    I = s[:,2]\n",
    "    Q = s[:,3]\n",
    "    R = s[:,4]\n",
    "    D = s[:,5]\n",
    "    SA = s[:,6]\n",
    "    \n",
    "    error = np.concatenate((D-Ddata, I - Idata))\n",
    "    return error\n",
    "\n",
    "# Helper to return data ever since first min_cases cases\n",
    "def select_region(df, fips, min_deaths=10):\n",
    "    d = df.loc[df['fips'] == fips]\n",
    "    start = np.where(d['deaths'].values >= min_deaths)[0][0]\n",
    "    d = d[start:]\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Actually predict deaths for a county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict deaths for county\n",
    "def predict_county(param_guesses, param_ranges, df, fips, min_deaths, predict_days):\n",
    "    data = select_region(df, fips, min_deaths)\n",
    "    res = least_squares(fit_leastsq_qd, param_guesses, args=(data,), bounds=np.transpose(np.array(param_ranges)))\n",
    "    \n",
    "    # Actual results\n",
    "    s = model_qd(res.x, data, len(data)+predict_days)\n",
    "    S = s[:,0]\n",
    "    E = s[:,1]\n",
    "    I = s[:,2]\n",
    "    Q = s[:,3]\n",
    "    R = s[:,4]\n",
    "    D = s[:,5]\n",
    "    SA = s[:,6]\n",
    "    return D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output formatting helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_dates(predictions, fips, start_date, predict_days):\n",
    "    '''\n",
    "    Input: (n,) array of predictions, fips code, start_date eg. 04-20-2020, and days to predict \n",
    "    Output: (n, 2) array of predictions labeled by date-FIPS\n",
    "    '''\n",
    "    start = datetime.strptime(start_date, '%m-%d-%Y')\n",
    "    data = predictions[len(predictions)-predict_days:]\n",
    "    result = []\n",
    "    for i, day_data in enumerate(data):\n",
    "        label = datetime.strftime(start + timedelta(i), '%m-%d-%Y') + '-' + str(fips)\n",
    "        dic = {'id':label, '50':day_data}\n",
    "        result.append(dic)\n",
    "    return result\n",
    "    \n",
    "    \n",
    "def predict_percentiles(data):\n",
    "    '''\n",
    "    Input: table of id, 50-pecentile prediction stored as list of dicts, keys('id', '50')\n",
    "    Output: table of ids and 10-90 percentiles stored as list of dictionaries\n",
    "    '''\n",
    "    output = []\n",
    "    for row in data:\n",
    "        label = row['id']\n",
    "        value = row['50']\n",
    "        \n",
    "        # generate samples for percentile\n",
    "        all_s = []\n",
    "        samples = 100\n",
    "        for i in range(samples):\n",
    "            sample = np.random.normal(loc=value, scale=np.sqrt(value))\n",
    "            all_s.append(sample)\n",
    "        \n",
    "        # row stored as dictionary\n",
    "        dic = {'id':label}\n",
    "        for j in range(10, 100, 10):\n",
    "            dic[str(j)] = np.percentile(all_s, j)\n",
    "        \n",
    "        output.append(dic)\n",
    "    return output\n",
    "\n",
    "def fill_with_default(start_date, fips, default_val, predict_days):\n",
    "    '''Return table of date_id with default percentiles, stored as list of dicts'''\n",
    "    start = datetime.strptime(start_date, '%m-%d-%Y')\n",
    "    result = []\n",
    "    for i in range(predict_days):\n",
    "        label = datetime.strftime(start + timedelta(i), '%m-%d-%Y') + '-' + str(fips)\n",
    "        dic = {'id':label}\n",
    "        for j in range(10, 100, 10):\n",
    "            dic[str(j)] = default_val\n",
    "        result.append(dic)\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SEIR output for each county\n",
    "#### Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_output(fips_list, df, sample_sub, start_date, \n",
    "                    param_guesses=None, param_ranges=None, min_deaths=2, predict_days=14):\n",
    "    '''\n",
    "    Input: list of FIPS codes, df with loaded data\n",
    "    Output: Submission df of 10-90 percentile predictions\n",
    "    '''\n",
    "    if param_guesses == None:\n",
    "        # parameters: beta, delta, gamma, alpha, lambda, kappa\n",
    "        constants = [2.0, 0.3, 0.2, 0.05, 0.2, 0.03]\n",
    "        # conditions: E, I, Q, R, SA\n",
    "        initial_conditions = [0.5e-3, 0.5e-3, 0.3e-3, 0.1e-4, 0.5]\n",
    "        param_guesses = constants + initial_conditions\n",
    "    \n",
    "    if param_ranges == None:\n",
    "        constants_ranges = [(0.5, 3.0), (0.0, 0.5), (0.0, 0.5), (0.01, 0.5), (0.0, 0.5), (0.005, 0.1)]\n",
    "        initial_ranges = [(1.0e-7, 0.01), (1.0e-7, 0.01), (1.0e-7, 0.01), (1.0e-7, 0.01), (1.0e-7, 0.9)]\n",
    "        param_ranges = constants_ranges + initial_ranges\n",
    "        \n",
    "    counties = df['fips']\n",
    "    for fips in tqdm(fips_list):\n",
    "        if fips not in counties:\n",
    "            output_rows = fill_with_default(start_date, fips, 0, predict_days)\n",
    "            for dic_row in output_rows:\n",
    "                sample_sub[sample_sub['id']==dic_row['id']] = dic_row.values()\n",
    "            del output_rows\n",
    "            continue\n",
    "        \n",
    "        latest_death = df[df['fips']==fips].iloc[-1]['deaths']\n",
    "        if latest_death < min_deaths:\n",
    "            output_rows = fill_with_default(start_date, fips, latest_death, predict_days)\n",
    "            for dic_row in output_rows:\n",
    "                sample_sub[sample_sub['id']==dic_row['id']] = dic_row.values()\n",
    "            del output_rows\n",
    "            continue\n",
    "        \n",
    "        raw_predict = predict_county(param_guesses, param_ranges, df, fips, min_deaths, predict_days)\n",
    "        formatted_predict = predict_percentiles(prediction_dates(raw_predict, fips, start_date, predict_days))\n",
    "        for dic_row in formatted_predict:\n",
    "            sample_sub[sample_sub['id']==dic_row['id']] = dic_row.values()\n",
    "        del raw_predict\n",
    "        del formatted_predict\n",
    "    \n",
    "    columns = ['id'] + [str(j) for j in range(10, 100, 10)]\n",
    "    return pd.DataFrame(output, columns=columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c768e441a13b423fa8c737aadad2d441",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=293293.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_output = generate_output(fips_list, df, sample_sub, '04-26-2020')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output.to_csv('gorgonio_output.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
